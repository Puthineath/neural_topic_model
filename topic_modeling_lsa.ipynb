{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modelling with LSA\n",
    "source: https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0    (EU 17 2017 establishment Union framework collection management use data fisheries sector Council Regulation (EC 1.With view (EU Regulation management biological, environmental, technical socioeco...\n1    Regulation (EU) 2019/833 European Parliament Council conservation enforcement measures Regulatory Area Northwest Atlantic Fisheries Organisation Regulation (EU Council Regulations EC (EC 1.This Re...\n2    Regulation (EU 1303/2013 European Parliament Council 17 December common provisions European Regional Development Fund European Social Fund Cohesion Fund European Agricultural Fund Rural Developmen...\n3    Regulation (EU) 2019/473 European Parliament Council 19 March 2019 European Fisheries Control Agency Regulation provision European Fisheries Control Agency the Agency operational coordination Memb...\ndtype: object"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/data1.csv\")\n",
    "features = data['title'] + \" \" + data['article']\n",
    "# Convert to list\n",
    "# features = features.tolist()\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-2e25eef9b144>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_features = features.str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    [establishment, union, framework, collection, management, data, fisheries, sector, council, regulation, view, regulation, management, biological, environmental, technical, socioeconomic, data, fis...\n1    [regulation, european, parliament, council, conservation, enforcement, measures, regulatory, area, northwest, atlantic, fisheries, organisation, regulation, council, regulations, regulation, union...\n2    [regulation, european, parliament, council, december, common, provisions, european, regional, development, fund, european, social, fund, cohesion, fund, european, agricultural, fund, rural, develo...\n3    [regulation, european, parliament, council, march, european, fisheries, control, agency, regulation, provision, european, fisheries, control, agency, agency, operational, coordination, states, com...\ndtype: object"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing everything except alphabets`\n",
    "def pre_processing(features):\n",
    "    new_features = features.str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "    # removing short words\n",
    "    new_features = new_features.apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "    # make all text lowercase\n",
    "    new_features = new_features.apply(lambda x: x.lower())\n",
    "\n",
    "    # tokenization\n",
    "    new_features = new_features.apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "\n",
    "    stop_words.extend(['programme','accordance','article', 'state','member','this','annex','paragraph'])\n",
    "    new_features = new_features.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    # # de-tokenization\n",
    "    # detokenized_doc = []\n",
    "    # for i in range(len(news_df)):\n",
    "    #     t = ' '.join(tokenized_doc[i])\n",
    "    #     detokenized_doc.append(t)\n",
    "    #\n",
    "    # news_df['clean_doc'] = detokenized_doc\n",
    "\n",
    "    return  new_features\n",
    "\n",
    "pre_processing(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Document-Term Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 100)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "max_features= 100, # keep top 100 terms\n",
    "max_df = 0.5,\n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(features)\n",
    "\n",
    "X.shape # check shape of the document-term matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent documents and terms in vectors\n",
    "svd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=122)\n",
    "\n",
    "svd_model.fit(X)\n",
    "\n",
    "len(svd_model.components_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "('inspection', 0.5458921720103344)\n",
      "('vessel', 0.42433304989011494)\n",
      "('director', 0.32659968907951076)\n",
      "('deployment', 0.2537436951796634)\n",
      "('scientific', 0.19465496309628796)\n",
      "('port', 0.1656213092988408)\n",
      "('flag', 0.16317756469331673)\n",
      "Topic 1: \n",
      "('scientific', 0.747621190790449)\n",
      "('groups', 0.25908587375138703)\n",
      "('funds', 0.20524221283240723)\n",
      "('fund', 0.18391834656410525)\n",
      "('esi', 0.13238566974904195)\n",
      "('committee', 0.1113511362400589)\n",
      "('examination', 0.10959282858156098)\n",
      "Topic 2: \n",
      "('funds', 0.3514757707807913)\n",
      "('fund', 0.31495880758278694)\n",
      "('esi', 0.2267094798542766)\n",
      "('subparagraph', 0.16036575994800092)\n",
      "('expenditure', 0.1599840427602731)\n",
      "('partnership', 0.1430247725255168)\n",
      "('instruments', 0.1362274480059432)\n",
      "Topic 3: \n",
      "('director', 0.4030157570075093)\n",
      "('inspection', 0.3520367742535239)\n",
      "('deployment', 0.30189538340494254)\n",
      "('scientific', 0.22051406947245353)\n",
      "('budget', 0.12391133417601838)\n",
      "('groups', 0.07155751606669539)\n",
      "('revenue', 0.05255205943651698)\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "# print(terms)\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t)\n",
    "\n",
    "        # print(\" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}